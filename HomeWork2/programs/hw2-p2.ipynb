{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. Add your name and HW Group Number below.\n",
    "2. Complete each question. Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", and delete and `throw NotImplementedError()` lines.\n",
    "3. Where applicable, run the test cases *below* each question to check your work. **Note**: In addition to the test cases you can see, the instructor may run additional test cases, including using *other datasets* to validate you code.\n",
    "4. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). You can also use the **Validate** button to run all test cases.\n",
    "5. Turn in your homework by going to the main screen in JupyterHub, clicking the Assignments menu, and submitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName: Vishnu Challa\\nHW Group Number: 40\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: Vishnu Challa\n",
    "HW Group Number: 40\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 2 Problem 2**\n",
    "\n",
    "In this workshop, you'll looking at evaluation metrics and hyperparameter turning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Loading Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91bb674dfa87ad40ae25f89b59196137",
     "grade": false,
     "grade_id": "cell-5edb17c9957ed27e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from sklearn import datasets\n",
    "# Remember you have to run this cell block before continuing!\n",
    "\n",
    "# set a seed for reproducibility\n",
    "random_seed = 25\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6aaf24896200c2102db04c3f2ee5b732",
     "grade": false,
     "grade_id": "cell-2fae64f787a55e35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "844011a9646584df739f7f6a94ca0fe6",
     "grade": false,
     "grade_id": "cell-307e8bfcba3ffd01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Meet the Metrics\n",
    "In this problem you will learn to calculate accuracy, precision, recall and f1-score for a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24b65278466835c5e1ea8f522a98a2cc",
     "grade": false,
     "grade_id": "cell-cc7c5aa8554728a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This is a dummy dataset that contains 500 positive and 500 negative samples\n",
    "X,Y = make_classification(n_samples=1000,n_features=4,flip_y=0,random_state=random_seed)\n",
    "\n",
    "test_data_fraction = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_data_fraction,  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "380e4535c28639b9437f0438b9602e80",
     "grade": false,
     "grade_id": "cell-3d0aea076a16d0e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Y_test_predicted = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed).fit(X=X_train, y=Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn provides different API to compute different metrics for classification problems. You have used accuracy_score() in homework 1. Here are some additional metrics you will be using in homework 2.\n",
    "\n",
    "- [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- [Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "- [Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "- [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bea3baf325c4ed55d6a21eb69bfd992",
     "grade": false,
     "grade_id": "classification_metrics",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    Use the metrics mentioned previously to build a function that computes all of them at the same time.\n",
    "    \n",
    "    Your inputs and outputs are as shown below:\n",
    "    Input:\n",
    "        y_true: A list or numpy array of the real class labels.\n",
    "        y_predicted: A list or numpy array of the predicted class labels.\n",
    "    Output:\n",
    "        accuracy: The calculated accuracy score.\n",
    "        precision: The calculated precision score.\n",
    "        recall: The calculated recall score.\n",
    "        f1: The calculated F1 score.\n",
    "        \n",
    "    Allowed Libraries: sklearn\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Calculate these metrics and assign the following variables\n",
    "    accuracy = precision = recall = f1 = None\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true, y_predicted, normalize=True)\n",
    "    precision = sklearn.metrics.precision_score(y_true, y_predicted, zero_division=1)\n",
    "    recall = sklearn.metrics.recall_score(y_true, y_predicted, zero_division=1)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_predicted, zero_division=1)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Precision (positive class): 0.9010989010989011\n",
      "Recall (positive class): 0.9213483146067416\n",
      "F1 (positive class): 0.9111111111111112\n"
     ]
    }
   ],
   "source": [
    "#Test your code!\n",
    "accuracy, precision, recall, f1 = classification_metrics(Y_test, Y_test_predicted)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision (positive class): {precision}')\n",
    "print(f'Recall (positive class): {recall}')\n",
    "print(f'F1 (positive class): {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b79c88d74308c5c2a82784ef7b5b67e",
     "grade": true,
     "grade_id": "cm_test_macro",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Public test for macro metrics\n",
    "accuracy, precision, recall, f1 = classification_metrics(Y_test, Y_test_predicted)\n",
    "np.testing.assert_almost_equal(accuracy, 0.92)\n",
    "np.testing.assert_almost_equal(precision, 0.9010989010989011)\n",
    "np.testing.assert_almost_equal(recall, 0.9213483146067416)\n",
    "np.testing.assert_almost_equal(f1, 0.9111111111111112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7da345248bfb7346033e8ca418d6ade",
     "grade": false,
     "grade_id": "cell-dc6bed57075e2d0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: Precision, Recall and F1-score also take an argument called `average`, which allows you to request the macro or micro average. It defaults to `binary`, which is just the value for the positive class only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83e705b2fca7bc0581590f28f65eb0e4",
     "grade": false,
     "grade_id": "cell-0f5a6e8bccbae8b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 Example: `classification_report`\n",
    "\n",
    "Below, we give an example of how to use the `classification_report` function to summarize a model's performance. Answer the question at the end.\n",
    "\n",
    "Sklearn also has a [built in function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) that will give a handy summary of all the popular classification metrics. You can use this for the later questions.\n",
    "\n",
    "Precision, Recall and F1 are reported for **each class separately**. For the \"0\" row, a 0 is treated as the positive class. For the \"1\" row, the 1 is treated as the positive class. This is helpful because Precision and Recall are both sensitive to which class is considered positive. **Support** is the number of instances of both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9358    0.9189    0.9273       111\n",
      "           1     0.9011    0.9213    0.9111        89\n",
      "\n",
      "    accuracy                         0.9200       200\n",
      "   macro avg     0.9184    0.9201    0.9192       200\n",
      "weighted avg     0.9203    0.9200    0.9201       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test,Y_test_predicted,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78d616614323c996557d15234b73b633",
     "grade": false,
     "grade_id": "cell-bfeb9d3246f2cb10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, let's compare some classifiers. Soon you'll learn about the K-nearest-neighbors and Adaboost classifiers. For now, all you need to know is that they're very different appraoches than decision tress, and you should expect them to have different perforamnce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9907    0.9550    0.9725       111\n",
      "           1     0.9462    0.9888    0.9670        89\n",
      "\n",
      "    accuracy                         0.9700       200\n",
      "   macro avg     0.9684    0.9719    0.9698       200\n",
      "weighted avg     0.9709    0.9700    0.9701       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Y_test_predicted = KNeighborsClassifier(n_neighbors=3).fit(X=X_train, y=Y_train).predict(X_test)\n",
    "print(\"KNN Classifer\")\n",
    "print(classification_report(Y_test,Y_test_predicted,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9537    0.9279    0.9406       111\n",
      "           1     0.9130    0.9438    0.9282        89\n",
      "\n",
      "    accuracy                         0.9350       200\n",
      "   macro avg     0.9334    0.9359    0.9344       200\n",
      "weighted avg     0.9356    0.9350    0.9351       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Y_test_predicted = AdaBoostClassifier(n_estimators=100, random_state=random_seed).fit(X=X_train, y=Y_train).predict(X_test)\n",
    "print(\"Adaboost Classifier\")\n",
    "print(classification_report(Y_test,Y_test_predicted,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b343e490628b7bc50a1c4f39cfb9717a",
     "grade": false,
     "grade_id": "cell-de12baceac197022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A *dummy classifier* always picks the majority. We use the to make sure a classifier is doing better than a naive approach that wouldn't require any real training (classifiers don't always do better!).\n",
    "\n",
    "What do the precision, recall and accuracy represent in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       111\n",
      "           1     0.4450    1.0000    0.6159        89\n",
      "\n",
      "    accuracy                         0.4450       200\n",
      "   macro avg     0.2225    0.5000    0.3080       200\n",
      "weighted avg     0.1980    0.4450    0.2741       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier (Picks the majority class. Every time.)\n",
    "from sklearn.dummy import DummyClassifier\n",
    "Y_test_predicted = DummyClassifier(strategy=\"most_frequent\", random_state=random_seed).fit(X=X_train, y=Y_train).predict(X_test)\n",
    "print(\"Dummy Classifier\")\n",
    "print(classification_report(Y_test,Y_test_predicted,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70d87bb5d5b9eed46d921962b88dc31c",
     "grade": false,
     "grade_id": "cell-b7f910cc06535f01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: If you get a warning above, that's normal. It's saying some metrics are \"ill-defined\" because the denominator is 0 (e.g. f1-score, because precision and recall are 0 for the 0-class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c82d5f752d88a3dac19f8dcb547b3fb6",
     "grade": false,
     "grade_id": "cell-cb58c764aba7e832",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's compare the classifiers. Which is the best? What metric are you using to compare them? Answer below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all the above \"K-nearest-neighbors\" classifier is the best because it has better F1-Score when compared to all the remaining classifiers. The reason why we are judging based on F1-Score is it is an harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6468aef2325f23628078806006d532ad",
     "grade": false,
     "grade_id": "cell-8db78dcac1da7590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.3 Example: Inspecting Imbalanced Data\n",
    "\n",
    "In this problem, you'll be trying to predict the presence of breast cancer from various features from medical readings. This can help doctors make better diagnoses and save lives.\n",
    "\n",
    "Breast cancer is a common canncer, but relatively rare overall. However, this dataset includes more positive instances (people with breast cancer) than negative. Why might that be the case?\n",
    "\n",
    "In this problem, we'll learn how to deal with these \"imbalanced\" datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9f13c208a01bd047e4f5c4f8974d376",
     "grade": false,
     "grade_id": "cell-ceb122c352c000dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.792037        0.703140             0.731113       0.686364   \n",
       "1          0.181768        0.203608             0.348757       0.379798   \n",
       "2          0.431017        0.462512             0.635686       0.509596   \n",
       "3          0.811361        0.565604             0.522863       0.776263   \n",
       "4          0.347893        0.463918             0.518390       0.378283   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                0.186816  ...       0.123934         0.506948    0.341575   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.601136           0.619292         0.568610              0.912027   \n",
       "1          0.347553           0.154563         0.192971              0.639175   \n",
       "2          0.483590           0.385375         0.359744              0.835052   \n",
       "3          0.915472           0.814012         0.548642              0.884880   \n",
       "4          0.437364           0.172415         0.319489              0.558419   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        0.598462                 0.418864     0.0  \n",
       "1        0.233590                 0.222878     0.0  \n",
       "2        0.403706                 0.213433     0.0  \n",
       "3        1.000000                 0.773711     0.0  \n",
       "4        0.157500                 0.142595     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "# Read the breast cancer prediction dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "bc_sk = datasets.load_breast_cancer()\n",
    "\n",
    "# Make sure data is in the same range\n",
    "bc_sk.data = MinMaxScaler().fit_transform(bc_sk.data)\n",
    "\n",
    "# Note that the \"target\" attribute is species, represented as an integer\n",
    "bc_data = pd.DataFrame(data= np.c_[bc_sk['data'], bc_sk['target']],columns= list(bc_sk['feature_names'])+['target'])\n",
    "bc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_fraction = 0.2\n",
    "bc_features = bc_data.iloc[:,0:-1]\n",
    "bc_labels = bc_data[\"target\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(bc_features, bc_labels, test_size=test_data_fraction,  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the ratio of class values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    357\n",
       "0.0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "752a38ee77fda1d51238a61665c80372",
     "grade": false,
     "grade_id": "cell-408d225bf1e0bc81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As we can see, it's around a 60/40 split. What effect do you think this will have on the various evaluation metrics? For example, how could a classifier easily get 100% recall, 60% accuracy and 60% precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get 100% recall the classifier should have zero false negatives and true negatives i.e it always predicts yes on the testing data and the 60% accuracy and 60% precision are due to the false positives present in the total sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3181f246102ac7447a6995a0a6959a61",
     "grade": false,
     "grade_id": "cell-a428af6dbbf4cc23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1.4: Holdout Evaluation Pipeline\n",
    "\n",
    "Before moving on to comparing different classifiers, you will implement a general pipeline for holdout model evaluation, which trains a model using training data and evaluates it on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08445ad39ab22f86b4739d8eb8482215",
     "grade": false,
     "grade_id": "train_eval_pipeline",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_evaluate_pipeline(x_train, y_train, x_test, y_test, model, digits=4):\n",
    "    \"\"\"\n",
    "    You will implement a pipeline that performs the following tasks:\n",
    "        1. Fit the model using x_train and y_train.\n",
    "        2. Use the model to predict labels y_predict for x_test.\n",
    "        3. Use classification_report to compute the metrics.\n",
    "        \n",
    "    Your inputs and outputs are as shown below:\n",
    "    \n",
    "    Input:\n",
    "        x_train: A numpy array of shape (n_training_rows, n_attributes) where n_training_rows refers to \n",
    "              the number of rows in your training dataset and n_attributes refers to the number of attributes. \n",
    "        y_train: A numpy array of shape (n_training_rows, ) containing the class labels for each row in your \n",
    "              training dataset.\n",
    "        x_test: A numpy array of shape (n_test_rows, n_attributes) where n_test_rows refers to the number \n",
    "              of rows in your target dataset and n_attributes refers to the number of attributes.\n",
    "        y_test: A numpy array of shape (n_test_rows, ) where n_test_rows refers to the number \n",
    "              of rows in your target dataset and n_attributes refers to the number of attributes.\n",
    "        model: A classifier model from sklearn. \n",
    "              Some example classifiers are: DecisionTreeClassifier, KNeighborsClassifier, AdaBoostClassifier, DummyClassifier\n",
    "        digits: An integer for classification_report() to control the number of digits printed.\n",
    "        \n",
    "    Output:\n",
    "        metric: A string of computed metrics returned by classification_report() to be printed out.\n",
    "    \"\"\"\n",
    "    y_test_predicted = model.fit(X=x_train, y=y_train).predict(x_test)\n",
    "    return classification_report(y_test,y_test_predicted,digits=digits)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the pipline for Decision Trees, KNN, Adaboost, and the Dummy Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9167    0.8462    0.8800        39\n",
      "         1.0     0.9231    0.9600    0.9412        75\n",
      "\n",
      "    accuracy                         0.9211       114\n",
      "   macro avg     0.9199    0.9031    0.9106       114\n",
      "weighted avg     0.9209    0.9211    0.9202       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "decision_tree_model = DecisionTreeClassifier(criterion=\"gini\", random_state=random_seed)\n",
    "decision_tree_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, decision_tree_model)\n",
    "print(\"Decision Tree\")\n",
    "print(decision_tree_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.8718    0.9315        39\n",
      "         1.0     0.9375    1.0000    0.9677        75\n",
      "\n",
      "    accuracy                         0.9561       114\n",
      "   macro avg     0.9688    0.9359    0.9496       114\n",
      "weighted avg     0.9589    0.9561    0.9553       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, knn_model)\n",
    "print(\"KNN Classifer\")\n",
    "print(knn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9714    0.8718    0.9189        39\n",
      "         1.0     0.9367    0.9867    0.9610        75\n",
      "\n",
      "    accuracy                         0.9474       114\n",
      "   macro avg     0.9541    0.9292    0.9400       114\n",
      "weighted avg     0.9486    0.9474    0.9466       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier(n_estimators=100, random_state=random_seed)\n",
    "ada_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, ada_model)\n",
    "print(\"Adaboost Classifier\")\n",
    "print(ada_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.0000    0.0000    0.0000        39\n",
      "         1.0     0.6579    1.0000    0.7937        75\n",
      "\n",
      "    accuracy                         0.6579       114\n",
      "   macro avg     0.3289    0.5000    0.3968       114\n",
      "weighted avg     0.4328    0.6579    0.5221       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\", random_state=random_seed)\n",
    "dummy_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, dummy_model)\n",
    "print(\"Dummy Classifier\")\n",
    "print(dummy_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1df9313489a8f4da4e7a482208ce59a6",
     "grade": true,
     "grade_id": "train_eval_pip_test_1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert decision_tree_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.9167    0.8462    0.8800        39\\n         1.0     0.9231    0.9600    0.9412        75\\n\\n    accuracy                         0.9211       114\\n   macro avg     0.9199    0.9031    0.9106       114\\nweighted avg     0.9209    0.9211    0.9202       114\\n'\n",
    "assert knn_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     1.0000    0.8718    0.9315        39\\n         1.0     0.9375    1.0000    0.9677        75\\n\\n    accuracy                         0.9561       114\\n   macro avg     0.9688    0.9359    0.9496       114\\nweighted avg     0.9589    0.9561    0.9553       114\\n'\n",
    "assert ada_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.9714    0.8718    0.9189        39\\n         1.0     0.9367    0.9867    0.9610        75\\n\\n    accuracy                         0.9474       114\\n   macro avg     0.9541    0.9292    0.9400       114\\nweighted avg     0.9486    0.9474    0.9466       114\\n'\n",
    "assert dummy_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.0000    0.0000    0.0000        39\\n         1.0     0.6579    1.0000    0.7937        75\\n\\n    accuracy                         0.6579       114\\n   macro avg     0.3289    0.5000    0.3968       114\\nweighted avg     0.4328    0.6579    0.5221       114\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea7e9973ae767506bb352cdd0d4a92bb",
     "grade": true,
     "grade_id": "train_eval_pip_test_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember there are hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcc03bebc8376e0ffd65d046533dd7f9",
     "grade": false,
     "grade_id": "cell-ca0cd39a79032396",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on these metrics, answer the following questions:\n",
    "\n",
    "1. Which model would you select and why? \n",
    "2. What metric(s) are most important for the breast cancer classification problem?\n",
    "3. How would you recommend a doctor actually use the model **in practice**? Is it good enough to make decisions on its own?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the above I would select \"KNeighborsClassifier\" as it has better F-1 Score from the others.\n",
    "2. For breast cancer classification problem \"Recall\" metric should be a greater value. Because in the prediction process predicting a false negative is costly rather than predicting a false positive. i.e. if we end up telling a cancer patient that he does not have cancer will impact his life where in if we say that a normal person is having cancer he might take precautions which will not cause any harm to him.\n",
    "3. I would recommend a doctor to use this model in practice because it has a higher recall value, which will help him to serve his patients better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b676e35947626a4ad91ea15f447d712c",
     "grade": false,
     "grade_id": "cell-d066ba0374589a0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.5 Multiclass Data\n",
    "\n",
    "Now, we'll be looking at the wine dataset, which has 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "466514f5155f4fe551165f385c5fd32a",
     "grade": false,
     "grade_id": "cell-b69a83ce1abfa086",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Read the wine dataset and translate to pandas dataframe\n",
    "wine_sk = datasets.load_wine()\n",
    "# Note that the \"target\" attribute is species, represented as an integer\n",
    "wine_data = pd.DataFrame(data= np.c_[wine_sk['data'], wine_sk['target']],columns= wine_sk['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f83f6beb3a1cce564fc06096b8928f46",
     "grade": false,
     "grade_id": "cell-bdae53bd27ab2c04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# The fraction of data that will be test data\n",
    "test_data_fraction = 0.90\n",
    "\n",
    "wine_features = wine_data.iloc[:,0:-1]\n",
    "wine_labels = wine_data[\"target\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(wine_features, wine_labels, test_size=test_data_fraction,  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    71\n",
       "0.0    59\n",
       "2.0    48\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec788c0ee8aa4ac4bb551d2bb0c45258",
     "grade": false,
     "grade_id": "cell-16ea2a61313be259",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The classes are represented as numbers. This is just shorthand to make it easier to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de77186bfecb97e8852a1756372d039a",
     "grade": false,
     "grade_id": "cell-a3c4556b8e203591",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) is useful for getting a broad overview of how your classifier handled certain classes.\n",
    "\n",
    "Note that according to the documentation, we should inerpret the output as follows:\n",
    "> By definition a confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$.\n",
    "\n",
    "So each row corresponds to the real class, and each column to the predicted class, from 0 to $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "320a316020c7e9ca1d45229d63fb70b1",
     "grade": false,
     "grade_id": "confusion_matrix",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26 31  0]\n",
      " [ 9 51  4]\n",
      " [ 4  2 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\"\"\"\n",
    "Here you will train a decision tree model using X_train and Y_train, predict the labels for Y_test, and\n",
    "compute its confusion matrix against the real labels.\n",
    "Store the computed confusion matrix in the variable named wine_decision_tree_confusion_matrix.\n",
    "\"\"\"\n",
    "\n",
    "wine_decision_tree_confusion_matrix = None\n",
    "Y_test_predicted = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed).fit(X=X_train, y=Y_train).predict(X_test)\n",
    "wine_decision_tree_confusion_matrix = confusion_matrix(Y_test, Y_test_predicted)\n",
    "print(wine_decision_tree_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06dee877f7d925501b19479b2632ddeb",
     "grade": true,
     "grade_id": "confusion_matrix_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(wine_decision_tree_confusion_matrix, np.array([[26, 31,  0],\n",
    "       [ 9, 51,  4],\n",
    "       [ 4,  2, 34]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the evaluation metrics as like above for Decision Trees, KNN, Adaboost, and the Dummy Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6667    0.4561    0.5417        57\n",
      "         1.0     0.6071    0.7969    0.6892        64\n",
      "         2.0     0.8947    0.8500    0.8718        40\n",
      "\n",
      "    accuracy                         0.6894       161\n",
      "   macro avg     0.7228    0.7010    0.7009       161\n",
      "weighted avg     0.6997    0.6894    0.6823       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "decision_tree_model = DecisionTreeClassifier(criterion=\"gini\", random_state=random_seed)\n",
    "decision_tree_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, decision_tree_model)\n",
    "print(\"Decision Tree\")\n",
    "print(decision_tree_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8889    0.8421    0.8649        57\n",
      "         1.0     0.5070    0.5625    0.5333        64\n",
      "         2.0     0.3333    0.3000    0.3158        40\n",
      "\n",
      "    accuracy                         0.5963       161\n",
      "   macro avg     0.5764    0.5682    0.5713       161\n",
      "weighted avg     0.5991    0.5963    0.5967       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, knn_model)\n",
    "print(\"KNN Classifer\")\n",
    "print(knn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9600    0.4211    0.5854        57\n",
      "         1.0     0.6146    0.9219    0.7375        64\n",
      "         2.0     0.9000    0.9000    0.9000        40\n",
      "\n",
      "    accuracy                         0.7391       161\n",
      "   macro avg     0.8249    0.7476    0.7410       161\n",
      "weighted avg     0.8078    0.7391    0.7240       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier(n_estimators=100, random_state=random_seed)\n",
    "ada_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, ada_model)\n",
    "print(\"Adaboost Classifier\")\n",
    "print(ada_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.0000    0.0000    0.0000        57\n",
      "         1.0     0.0000    0.0000    0.0000        64\n",
      "         2.0     0.2484    1.0000    0.3980        40\n",
      "\n",
      "    accuracy                         0.2484       161\n",
      "   macro avg     0.0828    0.3333    0.1327       161\n",
      "weighted avg     0.0617    0.2484    0.0989       161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/tljh/user/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\", random_state=random_seed)\n",
    "dummy_metrics = train_evaluate_pipeline(X_train, Y_train, X_test, Y_test, dummy_model)\n",
    "print(\"Dummy Classifier\")\n",
    "print(dummy_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "273e9495029e60fc99ac7e731039ae44",
     "grade": true,
     "grade_id": "train_eval_pip_test_3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert decision_tree_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.6667    0.4561    0.5417        57\\n         1.0     0.6071    0.7969    0.6892        64\\n         2.0     0.8947    0.8500    0.8718        40\\n\\n    accuracy                         0.6894       161\\n   macro avg     0.7228    0.7010    0.7009       161\\nweighted avg     0.6997    0.6894    0.6823       161\\n'\n",
    "assert knn_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.8889    0.8421    0.8649        57\\n         1.0     0.5070    0.5625    0.5333        64\\n         2.0     0.3333    0.3000    0.3158        40\\n\\n    accuracy                         0.5963       161\\n   macro avg     0.5764    0.5682    0.5713       161\\nweighted avg     0.5991    0.5963    0.5967       161\\n'\n",
    "assert ada_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.9600    0.4211    0.5854        57\\n         1.0     0.6146    0.9219    0.7375        64\\n         2.0     0.9000    0.9000    0.9000        40\\n\\n    accuracy                         0.7391       161\\n   macro avg     0.8249    0.7476    0.7410       161\\nweighted avg     0.8078    0.7391    0.7240       161\\n'\n",
    "assert dummy_metrics == '              precision    recall  f1-score   support\\n\\n         0.0     0.0000    0.0000    0.0000        57\\n         1.0     0.0000    0.0000    0.0000        64\\n         2.0     0.2484    1.0000    0.3980        40\\n\\n    accuracy                         0.2484       161\\n   macro avg     0.0828    0.3333    0.1327       161\\nweighted avg     0.0617    0.2484    0.0989       161\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37c9ba1483e445301d640a60cf750f70",
     "grade": false,
     "grade_id": "cell-a1cda4ef2e458a4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Answer the following questions below:\n",
    "\n",
    "1. Which model would you select if you cared equally about each class being correct? \n",
    "2. What if you cared most about accurately detecting Class 0? \n",
    "3. Would you ever choose the Decision Tree model over Adaboost? If so, when? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "512841c3939722b21a85349189df5a9e",
     "grade": true,
     "grade_id": "cell-3a41d9a672fa4959",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1. From the above result based on the F1 Score we should use AdaBoostClassifier for this case.\n",
    "2. I would prefer the class 0 to have higher precision, recall and F1 score values.\n",
    "3. In decision tree once the tree is constructed no matter how the testing sample varies it is fixed and the prediction logic is same, but when it comes to adaboost classifier it always keeps updating the wieghts and tries to fit the model according to the errors in prediction. This might lead to overfitting in some cases. In summary decision tree is a best option when the problem statement is well defined and subjected to very less changes in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eea248b0ca934ce8c791e657adee5a69",
     "grade": false,
     "grade_id": "cell-0a49b9dcf85ef5d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2 ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eaf6a5e8301880d0114f0cebd880f324",
     "grade": false,
     "grade_id": "cell-611f2cf243b3746d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Sklearn has some built in methods for [plotting ROC curves](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html).\n",
    "\n",
    "The dataset we'll be using for this exercise is the breast cancer dataset, which is used to tell if a certain individal might have breast cancer or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01bc04ccd40090c1cd23cb966b8403d8",
     "grade": false,
     "grade_id": "cell-e56ff27a22837dc1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.792037        0.703140             0.731113       0.686364   \n",
       "1          0.181768        0.203608             0.348757       0.379798   \n",
       "2          0.431017        0.462512             0.635686       0.509596   \n",
       "3          0.811361        0.565604             0.522863       0.776263   \n",
       "4          0.347893        0.463918             0.518390       0.378283   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                0.186816  ...       0.123934         0.506948    0.341575   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.601136           0.619292         0.568610              0.912027   \n",
       "1          0.347553           0.154563         0.192971              0.639175   \n",
       "2          0.483590           0.385375         0.359744              0.835052   \n",
       "3          0.915472           0.814012         0.548642              0.884880   \n",
       "4          0.437364           0.172415         0.319489              0.558419   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        0.598462                 0.418864     0.0  \n",
       "1        0.233590                 0.222878     0.0  \n",
       "2        0.403706                 0.213433     0.0  \n",
       "3        1.000000                 0.773711     0.0  \n",
       "4        0.157500                 0.142595     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "# Read the wine dataset and translate to pandas dataframe\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "bc_sk = datasets.load_breast_cancer()\n",
    "\n",
    "# Make sure data is in the same range\n",
    "bc_sk.data = MinMaxScaler().fit_transform(bc_sk.data)\n",
    "\n",
    "# Note that the \"target\" attribute is species, represented as an integer\n",
    "bc_data = pd.DataFrame(data= np.c_[bc_sk['data'], bc_sk['target']],columns= list(bc_sk['feature_names'])+['target'])\n",
    "bc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting our data\n",
    "test_data_fraction = 0.2\n",
    "bc_features = bc_data.iloc[:,0:-1]\n",
    "bc_labels = bc_data[\"target\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(bc_features, bc_labels, test_size=test_data_fraction,  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fd9b80adac814636660097069d54851",
     "grade": false,
     "grade_id": "cell-488b13155465b85e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Plotting ROC Curves\n",
    "\n",
    "In this section, you will use sklearn API to compute ROC curves and corresponding AUC value. Specifically, you can use [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) and [roc_auc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) to compute these values.\n",
    "\n",
    "**Hint** You may also want to take a look at the `predict_proba` function from different models such as [decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba) and [Ada boost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). You will need to reliy on part of its output since ROC is computed based on proabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a82b1f18850e35c2db041355db69d0d",
     "grade": false,
     "grade_id": "roc_auc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def roc_auc(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    In this function, you will need to implement the following steps.\n",
    "        1. Use model to compute its probability of predicting a sample as positive for each sample in x_test.\n",
    "        2. Use the computed probability and y_test to compute ROC curve and its AUC value.\n",
    "        \n",
    "    Your inputs and outputs are as shown below:\n",
    "    \n",
    "    Input:\n",
    "        model: A sklearn classifier instance. Assuming it has predict_proba() function.\n",
    "        x_test: A numpy array of shape (n_test_rows, n_attributes) where n_test_rows refers to the number \n",
    "              of rows in your target dataset and n_attributes refers to the number of attributes.\n",
    "        y_test: A numpy array of shape (n_test_rows, ) where n_test_rows refers to the number \n",
    "              of rows in your target dataset and n_attributes refers to the number of attributes.\n",
    "        \n",
    "    Output:\n",
    "        fpr: A list of increasing false positive rates as a part of ROC curve.\n",
    "        tpr: A list of increasing true positive rates as a part of ROC curve.\n",
    "        thresholds: A list of decreasing thresholds as a part of ROC curve.\n",
    "        auc: A single float value that is the computed AUC value.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.fit(X_train, Y_train)\n",
    "    lr_probs = model.predict_proba(x_test)\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    lr_auc = roc_auc_score(y_test, lr_probs, multi_class='ovr')\n",
    "    lr_fpr, lr_tpr, thresholds = roc_curve(y_test, lr_probs)\n",
    "    return lr_fpr, lr_tpr, thresholds, lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume a best ccp_alpha parameter\n",
    "best_alpha = 0.01\n",
    "\n",
    "# First fit a decision tree model and an Adaboost model\n",
    "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed, ccp_alpha=best_alpha).fit(X=X_train, y=Y_train)\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=random_seed).fit(X=X_train, y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f39a802fe48>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the ROC curves\n",
    "tree_fpr, tree_tpr, tree_thresh, tree_auc = roc_auc(gini_tree, X_test, Y_test)\n",
    "ada_fpr, ada_tpr, ada_thresh, ada_auc = roc_auc(ada, X_test, Y_test)\n",
    "\n",
    "plt.figure(0).clf()\n",
    "plt.plot(tree_fpr,tree_tpr,label=\"Decision Tree, auc=\"+str(tree_auc))\n",
    "plt.plot(ada_fpr,ada_tpr,label=\"Adaboost, auc=\"+str(ada_auc))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4d5ca9221adbca7418d381778e601d",
     "grade": true,
     "grade_id": "roc_auc_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_alpha = 0.01\n",
    "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed, ccp_alpha=best_alpha).fit(X=X_train, y=Y_train)\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=random_seed).fit(X=X_train, y=Y_train)\n",
    "\n",
    "tree_fpr, tree_tpr, tree_thresh, tree_auc = roc_auc(gini_tree, X_test, Y_test)\n",
    "ada_fpr, ada_tpr, ada_thresh, ada_auc = roc_auc(ada, X_test, Y_test)\n",
    "\n",
    "np.testing.assert_almost_equal(tree_fpr, [0.        , 0.02564103, 0.12820513, 0.25641026, 1.        ])\n",
    "np.testing.assert_almost_equal(tree_tpr, [0.        , 0.06666667, 0.97333333, 0.98666667, 1.        ])\n",
    "np.testing.assert_almost_equal(tree_thresh, [2.        , 1.        , 0.98127341, 0.11111111, 0.        ])\n",
    "assert tree_auc == 0.9184615384615386\n",
    "\n",
    "np.testing.assert_almost_equal(ada_fpr, [0.        , 0.        , 0.        , 0.02564103, 0.02564103,\n",
    "       0.05128205, 0.05128205, 0.07692308, 0.07692308, 0.1025641 ,\n",
    "       0.1025641 , 0.12820513, 0.12820513, 1.        ])\n",
    "np.testing.assert_almost_equal(ada_tpr, [0.        , 0.01333333, 0.74666667, 0.74666667, 0.77333333,\n",
    "       0.77333333, 0.78666667, 0.78666667, 0.86666667, 0.86666667,\n",
    "       0.98666667, 0.98666667, 1.        , 1.        ])\n",
    "np.testing.assert_almost_equal(ada_thresh, [1.84880167, 0.84880167, 0.62659665, 0.61650091, 0.61379135,\n",
    "       0.61073422, 0.60757132, 0.60626897, 0.58565245, 0.58018733,\n",
    "       0.53578899, 0.52133361, 0.45605993, 0.15915035])\n",
    "assert ada_auc == 0.9784615384615385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3374d9c5844362a1ff9872c345837bf6",
     "grade": true,
     "grade_id": "roc_auc_test_2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember there are hidden tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00e365dd4e4fdeb8bc222b19b07bbe64",
     "grade": false,
     "grade_id": "cell-4c6ed5f7c66aef81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Intepreting ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81f7e1898f6f0200d1cc32f6e8ece1b5",
     "grade": false,
     "grade_id": "cell-9f7497f03bb03d0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take a look at the above ROC curves. How are they similar? How do they differ? Is one strictly better than the other? In what situations is one better than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the above plot, when the false positives are less the area under the curve for AdaBoostClassifier is greater than the area under DecisionTreeClassifier and when the false positives gradually increase, the true positive rate for both the classifier almost converge with each other. Since in overall the AdaBoostClassifier has greater area over the DecisionTreeClassifier, AdaBoostClassifier is better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**: Make sure to complete all problems (.ipynb files) in this assignment. When you finish, double-check the submission instructions at the top of this file, and submit on JupyterHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
